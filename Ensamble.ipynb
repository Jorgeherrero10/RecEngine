{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from surprise import Reader, Dataset, SVD, SVDpp, NMF, accuracy, Prediction, AlgoBase, SlopeOne, KNNBasic\n",
    "from surprise.model_selection import train_test_split, cross_validate, KFold\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "my_seed = 1234\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "# Load the ratings data\n",
    "ratings_df = pd.read_csv('data/rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove -1 values (implicit feedback) to focus on explicit feedback only\n",
    "ratings_df = ratings_df[ratings_df['rating'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick 5% of users\n",
    "all_users = ratings_df['user_id'].unique()\n",
    "sample_size = int(0.05 * len(all_users))\n",
    "sampled_users = np.random.choice(all_users, size=sample_size, replace=False)\n",
    "\n",
    "# Filter ratings to keep only the sampled users\n",
    "ratings_sampled = ratings_df[ratings_df['user_id'].isin(sampled_users)]\n",
    "\n",
    "# Further sample data for efficiency if needed\n",
    "ratings_filtered_sample = ratings_sampled.sample(n=35000, random_state=my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scale of ratings\n",
    "min_rating = ratings_sampled['rating'].min()\n",
    "max_rating = ratings_sampled['rating'].max()\n",
    "\n",
    "# Create a Surprise Reader object\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "\n",
    "# Load the data into Surprise format\n",
    "anime_data = Dataset.load_from_df(ratings_sampled[['user_id', 'anime_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets (80% train, 20% test)\n",
    "trainset, testset = train_test_split(anime_data, test_size=.20, random_state=my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Mean Baseline\n",
    "class GlobalMeanBaseline(AlgoBase):\n",
    "    def __init__(self):\n",
    "        AlgoBase.__init__(self)\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        return self.trainset.global_mean\n",
    "    \n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        return self\n",
    "\n",
    "# Popular Items Baseline (already implemented in the RecSys project)\n",
    "class PopularBaseline(AlgoBase):\n",
    "    def __init__(self):\n",
    "        AlgoBase.__init__(self)\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        if i in self.mean_rating_per_item_df.index:\n",
    "            return self.mean_rating_per_item_df.loc[i]['rating']\n",
    "        else:\n",
    "            return self.trainset.global_mean\n",
    "    \n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        \n",
    "        ratings_df = pd.DataFrame([[i, r] for (_, i, r) in self.trainset.all_ratings()],\n",
    "                                  columns=['item', 'rating'])\n",
    "        \n",
    "        self.mean_rating_per_item_df = (ratings_df\n",
    "          .groupby('item')\n",
    "          .agg({'rating': 'mean'})\n",
    "        )\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline models\n",
    "global_mean_baseline = GlobalMeanBaseline()\n",
    "popular_baseline = PopularBaseline()\n",
    "\n",
    "# Train the baseline models\n",
    "global_mean_baseline.fit(trainset)\n",
    "popular_baseline.fit(trainset)\n",
    "\n",
    "# Make predictions\n",
    "global_predictions = global_mean_baseline.test(testset)\n",
    "popular_predictions = popular_baseline.test(testset)\n",
    "\n",
    "# Evaluate baseline performance\n",
    "print(\"Global Mean Baseline RMSE:\", accuracy.rmse(global_predictions))\n",
    "print(\"Popular Items Baseline RMSE:\", accuracy.rmse(popular_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensamble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "#!pip install cupy-cuda12x \n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from surprise import SVD, SVDpp, NMF, KNNBasic, KNNWithMeans, KNNWithZScore\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create base models\n",
    "def create_base_models(random_state=my_seed):\n",
    "    models = {\n",
    "        # Model-based CF approaches\n",
    "        'SVD': SVD(random_state=random_state),\n",
    "        'SVDpp': SVDpp(random_state=random_state),\n",
    "        'NMF': NMF(random_state=random_state),\n",
    "        \n",
    "        # Memory-based CF approaches\n",
    "        'KNN_Basic': KNNBasic(sim_options={'name': 'cosine', 'user_based': False}),\n",
    "        'KNN_Means': KNNWithMeans(sim_options={'name': 'pearson', 'user_based': False}),\n",
    "        'KNN_ZScore': KNNWithZScore(sim_options={'name': 'pearson', 'user_based': False}),\n",
    "        \n",
    "        # User-based approaches\n",
    "        'User_KNN_Basic': KNNBasic(sim_options={'name': 'cosine', 'user_based': True}),\n",
    "        'User_KNN_Means': KNNWithMeans(sim_options={'name': 'pearson', 'user_based': True})\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Create base models\n",
    "base_models = create_base_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train models and get predictions\n",
    "def train_and_predict(models, trainset, testset):\n",
    "    all_predictions = {}\n",
    "    all_models = {}\n",
    "    \n",
    "    for name, model in tqdm(models.items(), desc=\"Training Models\"):\n",
    "        # Train the model\n",
    "        start_time = time.time()\n",
    "        model.fit(trainset)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Make predictions\n",
    "        start_time = time.time()\n",
    "        predictions = model.test(testset)\n",
    "        predict_time = time.time() - start_time\n",
    "        \n",
    "        # Store predictions and trained model\n",
    "        all_predictions[name] = predictions\n",
    "        all_models[name] = model\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = accuracy.rmse(predictions)\n",
    "        print(f\"{name}: RMSE = {rmse:.4f}, Train Time = {train_time:.2f}s, Predict Time = {predict_time:.2f}s\")\n",
    "    \n",
    "    return all_predictions, all_models\n",
    "\n",
    "# Train models and get predictions\n",
    "print(\"Training base models and collecting predictions...\")\n",
    "all_predictions, all_models = train_and_predict(base_models, trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a meta-dataset for stacking\n",
    "def create_meta_dataset(all_predictions, testset):\n",
    "    # Create a dictionary to store all predictions\n",
    "    meta_data = {}\n",
    "    \n",
    "    # Organize predictions by user-item pair\n",
    "    for model_name, predictions in all_predictions.items():\n",
    "        for pred in predictions:\n",
    "            user = pred.uid\n",
    "            item = pred.iid\n",
    "            rating = pred.r_ui\n",
    "            estimated = pred.est\n",
    "            \n",
    "            # Create keys for each user-item pair\n",
    "            key = (user, item)\n",
    "            \n",
    "            if key not in meta_data:\n",
    "                meta_data[key] = {\n",
    "                    'actual': rating,\n",
    "                    'predictions': {}\n",
    "                }\n",
    "            \n",
    "            # Add this model's prediction\n",
    "            meta_data[key]['predictions'][model_name] = estimated\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    rows = []\n",
    "    for key, data in meta_data.items():\n",
    "        row = {'user': key[0], 'item': key[1], 'actual': data['actual']}\n",
    "        row.update(data['predictions'])\n",
    "        rows.append(row)\n",
    "    \n",
    "    meta_df = pd.DataFrame(rows)\n",
    "    return meta_df\n",
    "\n",
    "# Create meta dataset\n",
    "print(\"Creating meta-dataset for stacking...\")\n",
    "meta_df = create_meta_dataset(all_predictions, testset)\n",
    "print(f\"Meta-dataset shape: {meta_df.shape}\")\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data for meta-model\n",
    "X = meta_df.drop(['user', 'item', 'actual'], axis=1)\n",
    "y = meta_df['actual']\n",
    "\n",
    "# Split into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=my_seed)\n",
    "\n",
    "# Define meta-models\n",
    "meta_models = {\n",
    "    'Simple_Average': None,  # We'll implement this differently\n",
    "    'Weighted_Average': None,  # We'll implement this differently\n",
    "    'Linear_Regression': LinearRegression(),\n",
    "    'Ridge_Regression': Ridge(alpha=1.0),\n",
    "    'Random_Forest': RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=10, random_state=my_seed,\n",
    "        n_jobs=-1 if not cuda_available else 1  # Use all CPU cores if GPU not available\n",
    "    ),\n",
    "    'Gradient_Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=100, learning_rate=0.1, random_state=my_seed\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate meta-models\n",
    "meta_results = {}\n",
    "\n",
    "print(\"Training meta-models...\")\n",
    "for name, model in tqdm(meta_models.items(), desc=\"Training Meta-Models\"):\n",
    "    if name == 'Simple_Average':\n",
    "        # Simple average prediction\n",
    "        preds = X_val.mean(axis=1)\n",
    "        meta_results[name] = {\n",
    "            'model': None,\n",
    "            'predictions': preds,\n",
    "            'rmse': np.sqrt(mean_squared_error(y_val, preds))\n",
    "        }\n",
    "    \n",
    "    elif name == 'Weighted_Average':\n",
    "        # Weighted average based on individual model RMSE\n",
    "        weights = {}\n",
    "        for model_name in base_models.keys():\n",
    "            model_preds = [p.est for p in all_predictions[model_name]]\n",
    "            model_actual = [p.r_ui for p in all_predictions[model_name]]\n",
    "            rmse = np.sqrt(np.mean((np.array(model_actual) - np.array(model_preds)) ** 2))\n",
    "            # Inverse weighting - lower RMSE gets higher weight\n",
    "            weights[model_name] = 1 / rmse\n",
    "        \n",
    "        # Normalize weights\n",
    "        total = sum(weights.values())\n",
    "        weights = {k: v / total for k, v in weights.items()}\n",
    "        \n",
    "        # Apply weights\n",
    "        weighted_preds = np.zeros(len(X_val))\n",
    "        for model_name, weight in weights.items():\n",
    "            weighted_preds += X_val[model_name].values * weight\n",
    "        \n",
    "        meta_results[name] = {\n",
    "            'model': weights,\n",
    "            'predictions': weighted_preds,\n",
    "            'rmse': np.sqrt(mean_squared_error(y_val, weighted_preds))\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        preds = model.predict(X_val)\n",
    "        \n",
    "        # Store results\n",
    "        meta_results[name] = {\n",
    "            'model': model,\n",
    "            'predictions': preds,\n",
    "            'rmse': np.sqrt(mean_squared_error(y_val, preds))\n",
    "        }\n",
    "    \n",
    "    print(f\"{name}: RMSE = {meta_results[name]['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda_available:\n",
    "    print(\"Building GPU-accelerated ensemble...\")\n",
    "    \n",
    "    # Define a simple neural network meta-model\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    \n",
    "    class EnsembleNet(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(EnsembleNet, self).__init__()\n",
    "            self.layers = nn.Sequential(\n",
    "                nn.Linear(input_size, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(64, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(32, 1)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.layers(x)\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    input_size = X_train.shape[1]\n",
    "    model = EnsembleNet(input_size).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 50\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training NN Ensemble\"):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_loss = criterion(val_outputs, y_val_tensor)\n",
    "            \n",
    "            # Convert back to CPU for RMSE calculation\n",
    "            val_preds = val_outputs.cpu().numpy().flatten()\n",
    "            val_actual = y_val_tensor.cpu().numpy().flatten()\n",
    "            val_rmse = np.sqrt(mean_squared_error(val_actual, val_preds))\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}: Loss = {val_loss:.4f}, RMSE = {val_rmse:.4f}\")\n",
    "    \n",
    "    # Add NN results to meta_results\n",
    "    meta_results['Neural_Network'] = {\n",
    "        'model': model,\n",
    "        'predictions': val_preds,\n",
    "        'rmse': val_rmse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate final predictions\n",
    "def generate_final_predictions(testset, base_models, meta_model_name, meta_models, meta_results):\n",
    "    print(f\"Generating final predictions using {meta_model_name}...\")\n",
    "    \n",
    "    # Get the selected meta-model\n",
    "    meta_model = meta_results[meta_model_name]['model']\n",
    "    \n",
    "    # Store final predictions\n",
    "    final_predictions = []\n",
    "    \n",
    "    for uid, iid, r_ui in tqdm(testset, desc=\"Generating Final Predictions\"):\n",
    "        # Collect predictions from all base models\n",
    "        base_preds = {}\n",
    "        for name, model in base_models.items():\n",
    "            pred = model.predict(uid, iid)\n",
    "            base_preds[name] = pred.est\n",
    "        \n",
    "        # Make final prediction based on meta-model type\n",
    "        if meta_model_name == 'Simple_Average':\n",
    "            final_est = sum(base_preds.values()) / len(base_preds)\n",
    "        elif meta_model_name == 'Weighted_Average':\n",
    "            # Apply weights from meta_model (which contains weights)\n",
    "            final_est = sum(base_preds[name] * weight for name, weight in meta_model.items())\n",
    "        elif meta_model_name == 'Neural_Network':\n",
    "            # Create input tensor for neural network\n",
    "            X_test = torch.tensor([list(base_preds.values())], dtype=torch.float32).to(device)\n",
    "            with torch.no_grad():\n",
    "                final_est = meta_model(X_test).cpu().numpy()[0][0]\n",
    "        else:\n",
    "            # For sklearn models\n",
    "            X_test = np.array([list(base_preds.values())])\n",
    "            final_est = meta_model.predict(X_test)[0]\n",
    "        \n",
    "        # Ensure prediction is within rating scale\n",
    "        final_est = max(min(final_est, max_rating), min_rating)\n",
    "        \n",
    "        # Create prediction object\n",
    "        final_predictions.append(Prediction(uid, iid, r_ui, final_est, {}))\n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "# Select best meta-model based on validation RMSE\n",
    "best_meta_model = min(meta_results.items(), key=lambda x: x[1]['rmse'])[0]\n",
    "print(f\"Best meta-model: {best_meta_model} with RMSE = {meta_results[best_meta_model]['rmse']:.4f}\")\n",
    "\n",
    "# Generate final predictions\n",
    "final_predictions = generate_final_predictions(\n",
    "    testset, all_models, best_meta_model, meta_models, meta_results\n",
    ")\n",
    "\n",
    "# Calculate final RMSE\n",
    "final_rmse = accuracy.rmse(final_predictions)\n",
    "print(f\"Final Ensemble RMSE: {final_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance of individual models and ensemble\n",
    "def plot_model_comparison(all_predictions, final_predictions):\n",
    "    model_rmse = {}\n",
    "    for name, predictions in all_predictions.items():\n",
    "        model_rmse[name] = accuracy.rmse(predictions)\n",
    "    \n",
    "    # Add ensemble\n",
    "    model_rmse['Ensemble'] = accuracy.rmse(final_predictions)\n",
    "    \n",
    "    # Sort by RMSE\n",
    "    model_rmse = {k: v for k, v in sorted(model_rmse.items(), key=lambda item: item[1])}\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(model_rmse.keys(), model_rmse.values())\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('RMSE (lower is better)')\n",
    "    plt.title('Performance Comparison of Base Models vs Ensemble')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot model comparison\n",
    "plot_model_comparison(all_predictions, final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained models for future use\n",
    "def save_models(base_models, meta_model_name, meta_results):\n",
    "    print(\"Saving trained models...\")\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    import os\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    \n",
    "    # Save base models\n",
    "    for name, model in base_models.items():\n",
    "        with open(f'models/{name}_model.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "    \n",
    "    # Save meta model\n",
    "    meta_model = meta_results[meta_model_name]['model']\n",
    "    if meta_model_name != 'Neural_Network':\n",
    "        with open(f'models/meta_{meta_model_name}_model.pkl', 'wb') as f:\n",
    "            pickle.dump(meta_model, f)\n",
    "    else:\n",
    "        # For PyTorch model, save state dict\n",
    "        torch.save(meta_model.state_dict(), f'models/meta_{meta_model_name}_model.pt')\n",
    "    \n",
    "    print(\"Models saved successfully!\")\n",
    "\n",
    "# Save models\n",
    "save_models(all_models, best_meta_model, meta_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
